---
title       : Introduction to shinyHome
subtitle    : Product Pitch
author      : John James
job         : Coursera Building Data Products, Data Science Specialization
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      # 
widgets     : []
mode        : selfcontained # {standalone, draft}
knit        : slidify::knit2slides
ext_widgets : {rCharts: [libraries/nvd3]}

--- 

```{r environment, echo = FALSE, message = F, eval = T, tidy=TRUE, tidy.opts=list(comment=TRUE)}
require(rCharts)
options(RCHART_LIB = 'polycharts')
library(dplyr)
library(ggplot2)
library(plotly)
library(plyr)
library(rCharts)
```

## Explore Markets
Explore over 20,000 markets by geography, home value price ranges and growth rates, then examine the distribution of home values, and discover the top markets by home value growth and, for the top growth markets, a time series of price movements since 2000.  

<div style='text-align: center;'>
    <img height='400' src='http://www.daelmann.com/code/dataScience/shinyHome/images/explorer.png' />
</div>

--- 

## Analyze Markets
Analyze home value price trends for selected markets. Evaluate non-seasonal price trends and decompose seasonal movements into their trend, seasonal and random components.

<div style='text-align: center;'>
    <img height='400' src='http://www.daelmann.com/code/dataScience/shinyHome/images/analyzer.png' />
</div>

--- 

## Train Forecast Models
Select a market, create training and test sets, then train eight of the most acknowledged time series forecasting algorithms, including Arima, Basic Structural, Naive, Neural Networks, Automated forecasting with exponential smoothing and others. Inspect forecast error statistics to evaluate forecast accuracy of each model.

<div style='text-align: center;'>
    <img height='400' src='http://www.daelmann.com/code/dataScience/shinyHome/images/train.png' />
</div>

--- &twocol

## Forecast Home Value Prices
Execute forecasts and compare predictions among the algorithms.  This is the 10 year forecast of median home values for San Francisco, California for each of the predictional algorithms. On the right, we have the predicted prices on Jan 1, 2026 for each of the models.

*** {name: left}
```{r forecast, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
# Libraries
library(forecast)
library(ggplot2)
library(rCharts)
library(reshape)

# Get Time Series Data
hviAllCity  = read.csv("./processedData/hviAllCity.csv", header = TRUE, stringsAsFactors = FALSE)
d <- subset(hviAllCity, StateName == "California" & City == "San Francisco", select = X2000.01:X2015.12)
d <- d[,]/1000
v  <- as.numeric(as.vector(d))
d  <- ts(v, frequency = 12, start = c(2000,1))

#Train Models
ARIMA = auto.arima(d, ic='aicc', stepwise=FALSE)
ETS = ets(d, ic='aicc', restrict=FALSE)
NEURAL = nnetar(d, p=12, size=25)
TBATS = tbats(d, ic='aicc', seasonal.periods=12)
BATS = bats(d, ic='aicc', seasonal.periods=12)
STLM = stlm(d, s.window=12, ic='aicc', robust=TRUE, method='ets')
STS = StructTS(d, type = "level")
NAIVE = naive(d, 12)

# # Forecast
fcastARIMA   <-   forecast(ARIMA, 120)
fcastETS   <-   forecast(ETS, 120)
fcastNEURAL   <-   forecast(NEURAL, 120)
fcastTBATS   <-   forecast(TBATS, 120)
fcastBATS   <-   forecast(BATS, 120)
fcastSTLM   <-   forecast(STLM, 120)
fcastSTS   <-   forecast(STS, 120)
fcastNAIVE   <-   forecast(NAIVE, 120)

# Convert to numeric
fcastARIMA   <-   as.vector(as.numeric(fcastARIMA$mean))
fcastETS   <-   as.vector(as.numeric(fcastETS$mean))
fcastNEURAL   <-   as.vector(as.numeric(fcastNEURAL$mean))
fcastTBATS   <-   as.vector(as.numeric(fcastTBATS$mean))
fcastBATS   <-   as.vector(as.numeric(fcastBATS$mean))
fcastSTLM   <-   as.vector(as.numeric(fcastSTLM$mean))
fcastSTS   <-   as.vector(as.numeric(fcastSTS$mean))
fcastNAIVE   <-   as.vector(as.numeric(fcastNAIVE$mean))

timePeriod  <- seq.Date(as.Date('2016/1/1'), by = "month", length.out = 120) 
vars      <- c("TIME", "ARIMA", "ETS", "NAIVE", "NEURAL", "BATS", "TBATS", "STLM", "STS")
forecasts <- data.frame(timePeriod, fcastARIMA,	fcastETS,fcastNAIVE, fcastNEURAL, fcastBATS, fcastTBATS, fcastSTLM,	fcastSTS)
names(forecasts) <- vars
forecasts <- melt(forecasts, id = "TIME")
names(forecasts) <- c("Time", "Model", "Value")

# Plot Forecast
p <- nPlot(Value ~ Time, group = "Model", type = "lineChart", data = forecasts)
p$xAxis(
  tickFormat = 
    "#!
  function(d){
  f =  d3.time.format.utc('%Y-%m-%d');
  return f(new Date( d*24*60*60*1000 ));
  }
  !#"
)
p$yAxis(tickFormat = "#! function(d) {return d3.format(',.0f')(d)} !#")
p$yAxis(axisLabel = "($000)", width = 63)
p$params$width <- 350
p$params$height <- 400
print(p)
```

*** {name: right}
```{r prediction, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
#Get end of period prediction
fcastARIMA  <- fcastARIMA[length(fcastARIMA)]
fcastETS  <- fcastETS[length(fcastETS)]
fcastNEURAL  <- fcastNEURAL[length(fcastNEURAL)]
fcastTBATS  <- fcastTBATS[length(fcastTBATS)]
fcastBATS  <- fcastBATS[length(fcastBATS)]
fcastSTLM  <- fcastSTLM[length(fcastSTLM)]
fcastSTS  <- fcastSTS[length(fcastSTS)]
fcastNAIVE  <- fcastNAIVE[length(fcastNAIVE)]

#Plot end of period.
prediction <- as.vector(c(fcastARIMA,	fcastETS,	fcastNAIVE, fcastNEURAL,	fcastBATS, fcastTBATS,	fcastSTLM,	fcastSTS))
models <- c("Arima", "ETS", "Naive", "Neural", "BATS", "TBATS", "STLM", "STS")
d <- data.frame(models, prediction)
colnames(d) <- c("Model","Prediction")
p <- nPlot(Prediction~Model, data = d, type = "discreteBarChart", dom = "predictionPlot", height = 400, width = 350)
p$set(title = "Predicted Median Home Values at End of Forecast Period")
p$xAxis(staggerLabels = TRUE)
p$yAxis(tickFormat = "#! function(d) {return d3.format(',.0f')(d)} !#")
p$yAxis(axisLabel = "($000)", width = 60)
print(p)

```
